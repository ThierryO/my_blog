---
title: Using a variable both as fixed and random effect
author: Thierry Onkelinx
date: '2017-08-23'
slug: fixed-and-random
categories: ["statistics", "mixed-models"]
tags: ["lme4", "INLA"]
description: ''
images: []
menu: ''
output: 
  md_document:
    preserve_yaml: true
    variant: gfm
---

```{r setup, include=FALSE, cache = FALSE}
source("../../helpers.R")
opts_chunk$set(
  echo = FALSE,
  message = FALSE
)
```

One of the questions to answer when using mixed models is whether to use a variable as a fixed effect or as a random effect.
Sometimes it makes sense to use a variable both as fixed and random effect.
In this post I will try to make clear in which cases it can make sense and what are the benefits of doing so.
I will also handle cases in which it doesn't make sense.
Much will depend on the nature of the variable.
Therefore this post is split into three sections: categorical, discrete and continuous.
I will only display the most relevant parts of the code.
The full code is available on [GitHub](https:/github.com/thierryo/my_blog).

# Categorical variable

To make this clear, we start by creating a dummy dataset with 3 categorical covariates.
`B` is nested within `A`.
The resulting dataset is displayed in [fig 1](#cat-dummy).

```{r include = FALSE}
library(knitr)
library(ggplot2)
opts_chunk$set(
  cache = TRUE,
  autodep = TRUE,
  echo = TRUE, 
  dev = "svg"
)
```

```{r message = FALSE}
library(tidyverse)
library(lme4)
library(INLA)
```

```{r}
n_a <- 6
n_b <- 2
n_sample <- 3
sd_A <- 2
sd_B <- 1
sd_noise <- 1
dataset <- expand.grid(
  B = paste0("b", seq_len(n_a * n_b)),
  sample = seq_len(n_sample)
) %>%
  mutate(
    A = paste0("a", as.integer(B) %% n_a) %>%
      factor(),
    mu = rnorm(n_a, sd = sd_A)[A] + 
         rnorm(n_a * n_b, sd = sd_B)[B],
    Y = mu + rnorm(n(), sd = sd_noise)
  )

```

<a id="cat-dummy"></a>
```{r cat-dummy, fig.cap = "Fig 1. Dummy dataset with categorical variables.", echo = FALSE}
ggplot(dataset, aes(x = B, y = Y, colour = A)) +
  geom_point()
```

The first model is one that doesn't make sense.
Using a categorical variable both as random and a fixed effect.
In this case both effects are competing for the same information.
Below is the resulting fit from `lme4` and `INLA`.
Note the warning in the `lme4` output, the model failed to converge.
Nevertheless, both `lme4` and `INLA` yield the same parameter estimate ([fig. 2](#cat-fixed)), albeit the much wider confidence intervals for `lme4`.
The estimates for the random effects in both packages are equivalent to zero ([fig. 3](#cat-random)).
Again the `lme4` estimate has more uncertainty.

```{r}
model.1 <- lmer(Y ~ 0 + A + (1|A), data = dataset)
summary(model.1)
model.2 <- inla(Y ~ 0 + A + f(A, model = "iid"), data = dataset)
summary(model.2)
```

<a id="cat-fixed"></a>
```{r cat-fixed, fig.cap = "Fig 2. Comparison of fixed effects parameters for model `A + (1|A)`", echo = FALSE}
coef(summary(model.1)) %>%
  as.data.frame() %>%
  select(mean.1 = 1, se.1 = 2) %>%
  mutate(
    lcl.1 = qnorm(0.025, mean.1, se.1),
    ucl.1 = qnorm(0.975, mean.1, se.1)
  ) %>%
  bind_cols(
    model.2$summary.fixed %>%
      select(mean.2 = 1, lcl.2 = 3, ucl.2 = 5)
  ) %>%
  ggplot(
    aes(
      x = mean.1, xmin = lcl.1, xmax = ucl.1, 
      y = mean.2, ymin = lcl.2, ymax = ucl.2
    )
  ) +
  geom_abline(linetype = 3) +
  geom_point() +
  geom_errorbar() +
  geom_errorbarh() +
  xlab("lme4") +
  ylab("INLA")
```

<a id="cat-random"></a>
```{r cat-random, fig.cap = "Fig 3. Comparison of random effects parameters for model `A + (1|A)`", echo = FALSE}
rf.1 <- ranef(model.1, condVar = TRUE)$A
rf.1 %>%
  select(mean.1 = 1) %>%
  mutate(
    se.1 = attr(rf.1, "postVar") %>%
      as.vector() %>%
      sqrt(),
    lcl.1 = qnorm(0.025, mean.1, se.1),
    ucl.1 = qnorm(0.975, mean.1, se.1)
  ) %>%
  bind_cols(
    model.2$summary.random$A %>%
      select(mean.2 = 2, lcl.2 = 4, ucl.2 = 6)
  ) %>%
  ggplot(
    aes(
      x = mean.1, xmin = lcl.1, xmax = ucl.1, 
      y = mean.2, ymin = lcl.2, ymax = ucl.2
    )
  ) +
  geom_abline(linetype = 3) +
  geom_point() +
  geom_errorbar() +
  geom_errorbarh() +
  xlab("lme4") +
  ylab("INLA")
```

What if we want to add variable `B` as a nested random effect? We already know that adding `A` to both the fixed and the random effects is nonsense.
The correct way of doing this is to use `A` as a fixed effect and `B` as an [implicit nested](../../07/lme4-random-effects/#implicit-nesting) random effect.

```{r}
model.1 <- lmer(Y ~ 0 + A + (1|A/B), data = dataset)
summary(model.1)
model.1b <- lmer(Y ~ 0 + A + (1|B), data = dataset)
summary(model.1b)
model.2 <- inla(
  Y ~ 0 + A + f(A, model = "iid") + f(B, model = "iid"), 
  data = dataset
)
summary(model.2)
model.2b <- inla(Y ~ 0 + A + f(B, model = "iid"), data = dataset)
summary(model.2b)
```

# Discrete variable

## Intro

A discrete variable is a numerical variable but each interval between two values is an integer multiple of a fixed step size.
Typical examples are related to time, e.g. the year in steps of 1 year, months expressed in terms of years (step size 1/12), ...

We create a new dummy dataset with a discrete variable.
The response variable is a third order polynomial of the discrete variable.
The `X` variable is rescaled to -1 and 1.

```{r}
n_x <- 25
n_sample <- 10
sd_noise <- 10
dataset <- expand.grid(
  X = seq_len(n_x),
  sample = seq_len(n_sample)
) %>%
  mutate(
    mu =  0.045 * X ^ 3 - X ^ 2 + 10,
    Y = mu + rnorm(n(), sd = sd_noise),
    X = (X - ceiling(n_x / 2)) / floor(n_x / 2)
  )
```

<a id="discrete-dummy"></a>
```{r discrete-dummy, echo = FALSE, fig.cap = "Fig 4. Dummy dataset with a discrete variable. The line represents the true model."}
ggplot(dataset, aes(x = X, y = Y)) + 
  geom_line(aes(y = mu)) +
  geom_point()
```

## Fit with `lme4`

Suppose we fit a simple linear model to the data.
We know that this is not accurate because the real pattern is a third order polynomial.
And let's add the variable also as a random effect.
We use first `lme4` to illustrate the principle.
[Fig 5](#discrete-fit) illustrate how the fit of the fixed part is poor but the random effect of X compensates the fit.

```{r}
model.1 <- lmer(Y ~ X + (1|X), data = dataset)
summary(model.1)
```

<a id="discrete-fit"></a>
```{r discrete-fit, fig.cap = "Fig 5. Fitted values (line) and observed values (points) from the lme4 model.", echo = FALSE, warning = FALSE}
dataset %>%
  mutate(
    random = fitted(model.1),
    fixed = predict(model.1, re.form = NA)
  ) %>%
  gather("Type", "Fitted", random, fixed) %>%
  ggplot(aes(x = X, y = Fitted)) +
  geom_point(aes(y = Y)) +
  geom_line(aes(colour = Type))
```

The overall model fit improves when we add a second and third polynomial term.
And the variance of the random effect decreases.
It reduces even to zero once the third polynomial is in the model.
[Fig 6](#discrete-fit2) illustrates how the fit of the fixed effect improves when adding the higher order terms.
The effect on the fitted values with the random effect is marginal.

```{r}
model.1b <- lmer(Y ~ X + I(X ^ 2) + (1|X), data = dataset)
model.1c <- lmer(Y ~ X + I(X ^ 2) + I(X ^ 3) + (1|X), data = dataset)
anova(model.1, model.1b, model.1c)
summary(model.1b)
summary(model.1c)
```

<a id="discrete-fit2"></a>
```{r discrete-fit2, fig.cap = "Fig 6. Fitted values from the fixed and random part of the `lme4` models. Points represent the true model.", echo = FALSE, warning = FALSE}
dataset %>%
  select(X, mu) %>%
  mutate(
    random.1 = fitted(model.1),
    random.2 = fitted(model.1b),
    random.3 = fitted(model.1c),
    fixed.1 = predict(model.1, re.form = NA),
    fixed.2 = predict(model.1b, re.form = NA),
    fixed.3 = predict(model.1c, re.form = NA)
  ) %>%
  gather("Type", "Fitted", -X, -mu) %>%
  extract(Type, c("Type", "Order"), "(.*)\\.(.*)") %>%
  ggplot(aes(x = X, y = Fitted)) +
  geom_point(aes(y = mu)) +
  geom_line(aes(colour = Order)) +
  facet_wrap(~Type)
```

## Fit with `INLA`

`INLA` requires that we alter the data to get the same output.
First we copy `X` into `X.copy` because `inla` allows the variable to be used only once in the formula.
For some reason this wasn't needed with the categorical variables.
The `lme4` syntax `X + (1|X)` translates into the following `INLA` syntax: `X + f(X.copy, model = "iid")`.
Then next thing is that `INLA` does the model fitting and prediction in a single step.
Getting predictions for new data requires to add the new data to the original data while setting the response to `NA`.
If we want predictions for the fixed effect only, then we need to add rows were all random effect covariates are set to `NA`.
Hence `X.copy` must be `NA` while `X` must be non `NA`.
Note that this would be impossible without creating `X.copy`.

Let's fit the three same models with `INLA`.
The predictions are given in [fig 7](#discrete-fit3).
The results are very similar to the `lme4` results.

```{r}
dataset2 <- dataset %>%
  mutate(X.copy = X) %>%
  bind_rows(
    dataset %>%
      distinct(X, mu)
  )
```

```{r}
model.2 <- inla(
  Y ~ X + f(X.copy, model = "iid"), 
  data = dataset2, 
  control.compute = list(waic = TRUE)
)
model.2b <- inla(
  Y ~ X + I(X ^ 2) + f(X.copy, model = "iid"), 
  data = dataset2, 
  control.compute = list(waic = TRUE)
)
model.2c <- inla(
  Y ~ X + I(X ^ 2) + I(X ^ 3) + f(X.copy, model = "iid"), 
  data = dataset2, 
  control.compute = list(waic = TRUE)
)
```

<a id="discrete-fit3"></a>
```{r discrete-fit3, fig.cap = "Fig 7. Fitted values from the fixed and random part of the `INLA` models. Points represent the true model.", echo = FALSE, warning = FALSE}
dataset2 %>%
  mutate(
    fitted.1 = model.2$summary.fitted.values$mean,
    fitted.2 = model.2b$summary.fitted.values$mean,
    fitted.3 = model.2c$summary.fitted.values$mean,
    type = ifelse(is.na(Y), "fixed", "random")
  ) %>%
  gather("order", "fitted", fitted.1, fitted.2, fitted.3) %>%
  mutate(order = gsub("fitted.", "", order)) %>%
  ggplot(aes(x = X, y = fitted)) +
  geom_point(aes(y = mu)) +
  geom_line(aes(colour = order)) +
  facet_wrap(~type)
```

# Continuous variable

A continuous variable is a numeric variable where there is not fixed step size between two values.
In practice the step size will be several magnitudes smaller than the measured values.
Again let's clarify this with an example dataset.
For the sake of simplicity we'll reuse the true model from the example with the discrete variable.
Compare [fig 8](#continuous-dummy) with [fig 4](#discrete-dummy) and you'll see that [fig 8](#continuous-dummy) has no step size while [fig 4](#discrete-dummy) does.

```{r}
n_x <- 25
n_sample <- 10
sd_noise <- 10
dataset <- data.frame(
  X = runif(n_x * n_sample, min = 1, max = n_x)
) %>%
  mutate(
    mu =  0.045 * X ^ 3 - X ^ 2 + 10,
    Y = mu + rnorm(n(), sd = sd_noise),
    X = (X - ceiling(n_x / 2)) / floor(n_x / 2),
    X.copy = X
  )
```

<a id="continuous-dummy"></a>
```{r continuous-dummy, echo = FALSE, fig.cap = "Fig 8. Dummy dataset with a continuous variable. The line represents the true model."}
ggplot(dataset, aes(x = X, y = Y)) + 
  geom_line(aes(y = mu)) +
  geom_point()
```

The `lmer` model fails because the random effect has as many unique values as observations.

```{r}
tryCatch(
  lmer(Y ~ X + (1|X), data = dataset),
  error = function(e){e}
)
```

The `INLA` model yields output but the variance of the random effect is very high.
A good indicator that there is something wrong.

```{r}
model.2 <- inla(
  Y ~ X + f(X.copy, model = "iid"), 
  data = dataset, 
  control.compute = list(waic = TRUE)
)
inla.tmarginal(
  function(x){x^-1}, 
  model.2$marginals.hyperpar$`Precision for X.copy`
) %>%
  inla.zmarginal()
```

## Conclusion

- Using a variable both in the fixed and random part of the model makes only sense in case of a discrete variable.

## Session info

These R packages were used to create this post.

```{r}
sessioninfo::session_info()
```
