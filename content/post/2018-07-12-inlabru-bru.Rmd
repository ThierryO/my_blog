---
title: Comparing inlabru with INLA
author: ~
date: '2018-07-12'
slug: inlabru-bru
categories: ["statistics", "mixed-models"]
tags: ["inla", "inlabru"]
banner: ''
images: []
menu: ''
---

[`inlabru`](https://www.inlabru.org) is an R package which builds on top of the [`INLA`](https://www.r-inla.org) package. I had the opportunity to take a workshop on it during the International Statistical Ecology Workshop [ISEC2018](https://www.isec2018.org) in St Andrews. This was a five day workshop condensed into a single day, hence the pace was very high. It gave us a good overview of the possibilities of `inlabru` but no time to try it on our own data.

`inlabru` has two main functions: `bru` and `lgcp`. `bru` is a wrapper for `INLA::inla`. `lgcp` is intended to fit log Gaussian Cox processes. I will focus on `bru` and compare it with `INLA::inla` as I find that `bru` makes things a lot easier.

# Tundra bean goose

The test data is derived from the "Wintering waterbirds in Flanders, Belgium", freely available at GBIF (https://doi.org/10.15468/lj0udq). I've extracted the observations from the [tundra bean goose](https://www.gbif.org/species/6178319) (_Anser fabalis rossicus_, fig. \@ref(fig:tundra-bean-goose)). The dataset was limited to those locations with at leat 6 occurences during at least 3 years. Months with lower number of count were removed. Fig. \@ref(fig:observed-total) indicates the sum of all observed geese in the data. Note that these totals are somewhat misleading since there are a fair amount of missing observations (fig. \@ref(fig:missing)). The geographic distribution of the data is given in fig. \@ref(fig:map-goose).

```{r setup, include = FALSE}
library(knitr)
opts_chunk$set(
  cache = TRUE,
  autodep = TRUE,
  echo = TRUE,
  message = FALSE
)
library(htmlwidgets)
setWidgetIdSeed(20180712)
```

(ref:tundra-bean-goose) Tundra bean goose _Anser fabalis rossicus_ by [Roar Ottesen](https://www.gbif.org/occurrence/1798469433) CC BY 4.0

```{r tundra-bean-goose, fig.cap = "(ref:tundra-bean-goose)", echo = FALSE}
include_graphics("http://www.artsobservasjoner.no/MediaLibrary/2017/5/25dfef70-0a56-4f12-ad2e-77cbd4888615_image.jpg")
```

```{r load-packages}
library(scales)
library(tidyverse)
library(leaflet)
goose <- readRDS("../../data/20180712/anser_fabalis_rossicus.Rds")
set.seed(20180712)
```

```{r observed-total, fig.cap = "Time series of observed total counts for tundra bean goose", echo = FALSE}
goose %>%
  group_by(year, month) %>%
  summarise(observed = sum(count)) %>%
  ggplot(aes(x = year, y = observed, colour = month)) +
  geom_line()
```

```{r missing, fig.cap = "Time series of missingness in the data", echo = FALSE}
goose %>%
  complete(location_id, year, month) %>%
  group_by(year, month) %>%
  summarise(missing = mean(is.na(count))) %>%
  ggplot(aes(x = year, colour = month, y = missing)) +
  geom_line() +
  scale_y_continuous("proportion of missing counts", labels = percent)
```

```{r map-goose, fig.cap = "Map with the locations for tundra bean goose. The circle markers represent the centroid of the site. The area of the circle is proportional to the mean of the observed counts.", echo = FALSE}
goose %>%
  group_by(location_id, lat, long) %>%
  summarise(mean = mean(count)) %>%
  mutate(mean = 2 * sqrt(mean / pi)) %>%
  leaflet() %>%
  addTiles() %>%
  addCircleMarkers(radius = ~mean)
```

# `INLA` vs `inlabru`

## Fixed effects only

Let's start with a very simple model with contains only the year centered to the last year. The syntax of both models is very similar. `bru()` is a bit shorted because it returns both $WAIC$ and $DIC$ by default. The models are identical because `bru()` is just a wrapper for `inla()`. Their summary output is somewhat different in terms of lay-out and which information is given.

```{r load-inla}
library(INLA)
library(inlabru)
```

```{r fixed-continous}
goose %>%
  mutate(cyear = year - max(year)) -> goose
m0_inla <- inla(
  count ~ cyear, 
  data = goose, 
  family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
m0_inlabru <- bru(count ~ cyear, data = goose, family = "nbinomial")
summary(m0_inla)
summary(m0_inlabru)
```

A drawback is that `bru()` doesn't handle factor fixed effects as expected. Luckily it yields a warning about invalid factor levels. Unfortunaltly you don't get the warning when getting the summary. You need to be critical and notice that the parameters of the model are not what you would expect. The workaround is to convert the factor variable into a set of dummy variables and use those. Creating the dummy variable is straight forward with `model.matrix`. But adding them to the model is not very efficient when you have factor variables with more than a just few levels.

```{r fixed-factor}
m1_inla <- inla(
  count ~ cyear + month, 
  data = goose, 
  family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
m1_inlabru <- bru(count ~ cyear + month, data = goose, family = "nbinomial")
summary(m1_inla)
summary(m1_inlabru)
goose %>% 
  model.matrix(object = ~month) %>%
  as.data.frame() %>%
  select(-1) %>%
  bind_cols(goose) -> goose
m1_inlabru <- bru(
  count ~ cyear + monthdec + monthjan + monthfeb, 
  data = goose, 
  family = "nbinomial"
)
summary(m1_inlabru)
```

## Random effects

`inla()` use the `f()` function to specify the random effects. `bru()` is very liberal and allows the user to choose any name, as long as it is a valid function name. In the example below we use `site`. For more detail see `help("bru.components")`. The downside is that `bru()` requires integer coded levels which go from 1 to the number of levels. We use the `as.integer(factor())` trick to get these indices. Furthermore you need to supply the number of levels in the random effect for some random effects models.

```{r random-iid}
comp_inla <- count ~ cyear + month + f(location_id, model = "iid")
m2_inla <- inla(
  comp_inla, data = goose, family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
goose %>%
  mutate(
    loc_id = factor(location_id) %>%
      as.integer()
  ) -> goose
n_loc <- max(goose$loc_id)
comp_inlabru <- count ~ cyear + monthdec + monthjan + monthfeb + 
  site(map = loc_id, model = "iid", n = n_loc)
m2_inlabru <- bru(comp_inlabru, data = goose, family = "nbinomial")
summary(m2_inla)
summary(m2_inlabru)
```

The use of user defined names for random effect functions has the benefit that you can use the same variable multiple times in the model. `inla()` requires unique names and hence copies of the variable. The `map` argument also allows to use a function of a variable, thus removing the need of creating a new variable. The `model = "linear"` is another way of specifying a continuous fixed effect. See http://www.r-inla.org/models/latent-models for an overview of all available latent models in INLA.

```{r random-alternatives}
goose %>%
  mutate(
    cyear = cyear - min(cyear) + 1,
    cyear2 = cyear
  ) -> goose2
n_year <- max(goose2$cyear)
comp_inla <- count ~ cyear + f(cyear2, model = "iid") + 
  month + f(location_id, model = "iid")
m3_inla <- inla(
  comp_inla, data = goose2, family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
comp_inlabru <- count ~ cyear + rtrend(map = cyear, model = "iid", n = n_year) +
  monthdec + monthjan + monthfeb + site(map = loc_id, model = "iid", n = n_loc)
m3_inlabru <- bru(comp_inlabru, data = goose2, family = "nbinomial")
comp_inlabru <- count ~ 
  lintrend(map = cyear, model = "linear") + 
  quadtrend(map = cyear ^ 2, model = "linear") +
  rtrend(map = cyear, model = "iid", n = n_year) +
  monthdec + monthjan + monthfeb + site(map = loc_id, model = "iid", n = n_loc)
m3_inlabru2 <- bru(comp_inlabru, data = goose2, family = "nbinomial")
summary(m3_inlabru2)
```

## Meshed random effects

One of the great benefits of `inlabru` is that it makes it much easier to work with random effects on a mesh. The current data are geographic coordinates in "WGS84". For this analysis we want them in a projected coordinate system. "Belgian Lambert 72" [EPSG:31370](https://epsg.io/31370) is a relevant choice. Therefore we convert the data into a `SpatialPointsDataFrame` and transform it to EPSG:31370.

Instead of using a convex hull of the locations, we will use the administrative borders of [Flanders](https://en.wikipedia.org/wiki/Flanders) as a boundary for the mesh. The simplified version of this border is the blue line in fig. \@ref(fig:flanders-mesh)). Note that the mesh extents this border because that reduces potential edge effects. The detail of the mesh is defined by `cutoff` and `max.edge`, the former defines the minimal length of each edge and the latter the maximal length. These lengths have the same units as the coordinate system, in this case meters. We pass two numbers for both arguments. The first refers to the edges inside the boundary, the second to edges outside the boundary. This creates larger triangles outside the boundary, which will speed up the computation.

```{r flanders-mesh, fig.cap = "Mesh for Flanders. Red circles indicate the sites.", message = FALSE}
SpatialPointsDataFrame(
  coords = goose %>%
    select(long, lat),
  data = goose %>%
    select(loc_id, year, month, count, monthdec, monthjan, monthfeb),
  proj4string = CRS("+proj=longlat +datum=WGS84")
) %>%
  spTransform(CRS("+init=epsg:31370")) -> goose_lambert
library(rgdal)
readOGR("../../data/20180712/vlaanderen.shp") -> flanders
as.inla.mesh.segment(flanders) -> flanders_segment
inla.mesh.2d(
  boundary = flanders_segment, 
  max.edge = c(10e3, 20e3), 
  cutoff = c(5e3, 10e3)
) -> flanders_mesh
ggplot() +
  gg(flanders_mesh) +
  gg(goose_lambert, col = "red") +
  coord_fixed()
```

Once the mesh is defined, we can create the [stochastic partial differential equation](https://en.wikipedia.org/wiki/Stochastic_partial_differential_equation) SPDE model. In this case we define it using a [Mat√©rn covariance function](https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function).

```{r}
flanders_spde <- inla.spde2.pcmatern(
  flanders_mesh,
  prior.range = c(1, 0.01),
  prior.sigma = c(4, 0.01)
)
```

All steps upto this point are needed for both `INLA::inla()` and `inlabr::bru()`. In case of `INLA::inla()` you need use `inla.spde.make.A()` to define a project matrix. This matrix maps the coordinates of the observation to the three nodes of the triangle in which it is located. In the special case that the observation is on a edge it will map to the two nodes defining the edge, or the node itself in case the observation coincides with a node. Then you need to define a `inla.stack()`, which is passed to the `data` argument after transforming it with `inla.stack.data()`. The SPDE object is used as `model` in the random effect 'site'.

The same model is much easier with `inlabr::bru()`. In this case you need to pass a `SpatialPointsDataFrame` to the `data` argument. The random effect 'site' has the SPDE object as `model` and uses "coordinates" as `map`. In this case there is no object "coordinates" in the data, hence `inlabr::bru()` will look in the environment and finds the `sp::coordinates()` function. This functions returns the coordinates of a `SpatialPointsDataFrame`, so `inlabr::bru()` has all the information it needs to map the observations to the SPDE object.

```{r eval = FALSE}
## INLA
A <- inla.spde.make.A(mesh = flanders_mesh, loc = goose_lambert)
goose_stack <- inla.stack(
  tag = 'estimation', ## tag
  data = list(count = goose$count), ## response
  A = list(A, 1), ## two projector matrices (SPDE and fixed effects)
  effects = list(## two elements:
    site = seq_len(flanders_spde$n.spde), ## RF index
    goose %>%
      select(cyear, month)
  )
)
comp_inla <- count ~ 0 + month + cyear +
  f(site, model = flanders_spde)
m4_inla <- inla(
  comp_inla, 
  data = inla.stack.data(goose_stack), family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE),
  control.predictor = list(A = inla.stack.A(goose_stack))
)

# inlabru
comp_inlabru <- count ~ monthdec + monthjan + monthfeb + cyear +
  site(map = coordinates, model = flanders_spde)
m4_inlabru <- bru(comp_inlabru, data = goose_lambert, family = "nbinomial")
```

We can also create 1 dimensional meshes. This is useful for line transects or (irregural) time series.

```{r}
trend_mesh <- inla.mesh.1d(min(goose$year):max(goose$year), boundary = "free")
trend_spde <- inla.spde2.pcmatern(
  trend_mesh,
  prior.range = c(1, 0.5),
  prior.sigma = c(4, 0.01)
)
comp_inlabru <- count ~ monthdec + monthjan + monthfeb +
  trend(map = year, model = trend_spde) +
  site(map = coordinates, model = flanders_spde)
m4b_inlabru <- bru(comp_inlabru, data = goose_lambert, family = "nbinomial")
```

## Plotting the model

`plot.inla()` is an easy way to generate most of the relevant plots with a single command. It will open several plot windows to keep the plots readable. However this doesn't work well in combination with Rmarkdown. `plot.bru()` has the opposite phylosophy: you get the plot of only one component. Getting a plot for all components is a bit more tedious, but the advantage is that you can use it in combination with Rmarkdown. Another nice feature is that `plot.bru()` returns `ggplot2` object. So they are easy to adapt, see e.g. fig. \@ref(fig:plot-fixed). `inlabru` also provides a `multiplot()` function whcih can be used to combine several plots.

```{r rw1-models}
pc_prior <- list(theta = list(prior = "pc.prec", param = c(1, 0.01)))
goose %>%
  mutate(iyear = cyear - min(cyear) + 1) -> goose
n_year <- max(goose$iyear)
comp_inla <- count ~ month + 
  f(cyear, model = "rw1", hyper = pc_prior) + 
  f(location_id, model = "iid", hyper = pc_prior)
m5_inla <- inla(
  comp_inla, data = goose, family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
comp_inlabru <- count ~ monthdec + monthjan + monthfeb + 
  trend(map = iyear, model = "rw1", n = n_year, hyper = pc_prior) +
  site(map = loc_id, model = "iid", n = n_loc, hyper = pc_prior)
m5_inlabru <- bru(comp_inlabru, data = goose, family = "nbinomial")
```

```{r eval = FALSE}
plot(m5_inla)
```

```{r plot-fixed, fig.cap = "Posterior density plots of the fixed effects"}
p_intercept <- plot(m5_inlabru) + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthdec <- plot(m5_inlabru, "monthdec") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthjan <- plot(m5_inlabru, "monthjan") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthfeb <- plot(m5_inlabru, "monthfeb") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
multiplot(p_intercept, p_monthdec, p_monthjan, p_monthfeb)
```

```{r, fig.cap = "Posterior density of the trend random intercepts."}
plot(m5_inlabru, "trend")
```

```{r fig.cap = "Posterior density of the site random intercepts."}
plot(m5_inlabru, "site")
```

### Plotting meshes

The mesh effects can be plot in a similar way. The default plot will display the estimate effect at each node. While this can be useful for 1D plot with a small number of nodes (top of fig. \@ref(fig:mesh-plot)), this is not useful for 2D meshes or meshed with a large number of nodes (bottom of fig. \@ref(fig:mesh-plot)). Looking at the posterior distributions for the range and the variance of the Mat√©rn covariance structure of SPDE model makes more sense (fig. \@ref(fig:mesh-range-var)). Or plot the actual Mat√©rn functions (fig. \@ref(fig:matern-function)).

```{r mesh-plot, fig.cap = "Posterior density of the random intercepts at the nodes of the mesh."}
p_trend <- plot(m4b_inlabru, "trend")
p_site <- plot(m4b_inlabru, "site")
multiplot(p_trend, p_site)
```

```{r mesh-range-var, fig.cap = "Posterior distributions of the range and log variance of the Mat√©rn covariace for the sites."}
spde.range <- spde.posterior(m4b_inlabru, "site", what = "range")
spde.logvar <- spde.posterior(m4b_inlabru, "site", what = "log.variance")
range.plot <- plot(spde.range)
var.plot <- plot(spde.logvar)
multiplot(range.plot, var.plot)
```

```{r matern-function, fig.cap = "Fitted Mat√©rn covariance and correlation functions."}
spde.posterior(m4b_inlabru, "site", what = "matern.covariance") %>%
  plot() +
  xlab("distance") +
  ylab("covariance") -> covplot
spde.posterior(m4b_inlabru, "site", what = "matern.correlation") %>%
  plot()  +
  xlab("distance") +
  ylab("correlation") -> corplot
multiplot(covplot, corplot)
```

# Predictions

`INLA` has, unlike most R packages, no `predict()` function. So `INLA` can't do predictions? No, it can do prediction but it does that simultaneously with fitting the model. This implies that you need to add the observations for which you want prediction to the data prior to the model fitting. Setting the response variable to `NA` avoid that these observation influcence the model parameters. A huge downside of this is, that you need to plan ahead and carefully prepare your data. If you forget some prediction, you will have to fit the model again. 

The `predict()` function in most R packages split the model fitting and the prediction in two separate steps. Getting prediction for another data set does not require to refit the model. `inlabru` provided a `predict()` function for `bru`, `lgcp` and `inla` models. The fitting works slightly different in `INLA` and `inlabru`. When the observations for the prediction are available at the time of the model fitting, then the full posterior of those observations becomes available. `inlabru::predict.inla()` works by repeatetly sampling the posterior distributions of the parameters and use each sample to calculate a predicted values. This yields a sampled posterior distribution for the fitted value of the observations.

`predict.bru()` requires at leat three arguments: `object` the fitted model; `data` the new observations for which you want a prediction and `formula` the components of the model you want to use in the predictions. The example below calculates the predictions for only the trend component. Note that the predict function returns the `data` and adds several columns with relevant information on the prediction. The names of these columns are more efficient than those returned by `INLA`: `q0.025` is a valid name for an R object, wereas `0.025quant` isn't. Another nice feather is that you can incorporate the prediction directly into a ggplot2 plot.

```{r}
goose %>%
  distinct(year, iyear) %>%
  predict(object = m5_inlabru, formula = ~ trend) -> pred_trend_log
# predictions from inlabru
glimpse(pred_trend_log)
# fitted value from INLA
glimpse(m5_inla$summary.fitted.values)
```

```{r fig.cap = "Predicted effect of 'trend' on the link scale"}
ggplot() +
  gg(pred_trend_log) +
  geom_hline(yintercept = 0, linetype = 2)
```

The default prediction are on the link scale, which is the log link in this case. Backtransformation is straightforward, just add the backtransformation function to the formula.

```{r fig.cap = "Predicted effect of 'trend' on the natural scale"}
goose %>%
  distinct(year, iyear) %>%
  predict(object = m5_inlabru, formula = ~ exp(trend)) -> pred_trend_natural
ggplot() +
  gg(pred_trend_natural) +
  geom_hline(yintercept = 1, linetype = 2)
```

The `gg()` solutions works only in case of a single covariate. With multiple covariate you have to create the plot manually. But that is not very hard given the nice format of the output returned by `predict.bru()`.

```{r fig.cap = "Predicted average expected mean of the counts."}
goose %>%
  distinct(year, month, iyear, monthdec, monthjan, monthfeb) %>%
  predict(
    object = m5_inlabru, 
    formula = ~ exp(Intercept + trend + monthdec + monthjan + monthfeb)
  ) -> pred_trend_month
ggplot(pred_trend_month, aes(x = year, y = mean, ymin = q0.025, ymax = q0.975)) +
  geom_ribbon(aes(fill = month), alpha = 0.1) +
  geom_line(aes(colour = month))
```

Another very neat feature is that you can take both the model uncertainty as the natural variability into account. The model estimates the mean of the negative binomial distribution. The variability of this mean only includes the model uncertainty. In case we are interested in the total variability in the count, we need to plug this mean into the distribution. Below is an example on how to do this. AFAIK this works only for a single prediction. The result yields the distribution of the counts. `inla.zmarginal` is used to calculate the mean and the quantiles of this distribution. Please to that is not entirely correct as we are ignoring the variability of the dispersion parameter of the negative binomial distribution. I'm not sure how to incorporate that at the moment.

(ref:distN) Distribution of the average counts for the last year in January. Dashed lines indicate the mean, 2.5% and 97.5% quantiles.

```{r, fig.cap = "(ref:distN)"}
size <- 1 / m5_inlabru$summary.hyperpar[1, "mean"]
goose %>%
  distinct(year, iyear, month, monthjan) %>%
  filter(year == max(year), month == "jan") %>%
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      N = 0:450,
      dnbinom(
        0:450,
        size = size,
        mu = exp(Intercept + trend + monthjan)
      )
    ),
    n.samples = 1e2
  ) -> pred_trend_natural_N
pred_trend_natural_N %>%
  select(x = N, y = mean) %>%
  as.list() %>%
  inla.zmarginal(silent = TRUE) %>%
  unlist() -> quants
ggplot(pred_trend_natural_N, aes(x = N, y = mean)) +
  geom_line() +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")],
    linetype = 2
  )
```

(ref:distN2) Distribution of the average counts for the last year in January. Dashed lines indicate the mean, 2.5% and 97.5% quantiles. Black lines are based on 100 samples, red lines on 1000 samples.

```{r fig.cap = "(ref:distN2)"}
goose %>%
  distinct(year, iyear, month, monthjan) %>%
  filter(year == max(year), month == "jan") %>%
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      N = 0:450,
      dnbinom(
        0:450,
        size = size,
        mu = exp(Intercept + trend + monthjan)
      )
    ),
    n.samples = 1e3
  ) -> pred_trend_natural_N2
pred_trend_natural_N2 %>%
  select(x = N, y = mean) %>%
  as.list() %>%
  inla.zmarginal(silent = TRUE) %>%
  unlist() -> quants2
ggplot(pred_trend_natural_N, aes(x = N, y = mean)) +
  geom_line() +
  geom_line(data = pred_trend_natural_N2, colour = "red") +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")],
    linetype = 2
  ) +
  geom_vline(
    xintercept = quants2[c("mean", "quant0.025", "quant0.975")],
    linetype = 2,
    colour = "red"
  )
```

We can also use aggregations in the formula. Let's say we want to estimate the total number of birds over all sites at a given year and month. The example below illustrated how you can use aggregation.

(ref:distN3) Distribution of the total counts for the last year in January. Dashed lines indicate the mean, 2.5% and 97.5% quantiles.

```{r fig.cap = "(ref:distN3)"}
# total of expected counts
goose %>%
  filter(year == max(year), month == "jan") %>%
  predict(
    object = m5_inlabru, 
    formula = ~ sum(exp(Intercept + trend + monthdec + monthjan + monthfeb + site))
  ) -> pred_total
glimpse(pred_total)
# distribution of total counts
low <- qnbinom(0.001, mu = pred_total$q0.025, size = size)
high <- qnbinom(0.999, mu = pred_total$q0.975, size = size)
goose %>%
  filter(year == max(year), month == "jan") %>%
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      N = low:high,
      dnbinom(
        low:high,
        size = size,
        mu = sum(exp(Intercept + trend + monthdec + monthjan + monthfeb + site))
      )
    )
  ) -> pred_total_natural
pred_total_natural %>%
  select(x = N, y = mean) %>%
  as.list() %>%
  inla.zmarginal(silent = TRUE) %>%
  unlist() -> quants
ggplot(pred_total_natural, aes(x = N, y = mean)) +
  geom_line() +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")],
    linetype = 2
  )
```

We can make predictions for the mesh as well. 

```{r fig.cap = "Relative effect of the spatial field of the sites."}
pred_mesh <- predict(m4b_inlabru, pixels(flanders_mesh), ~exp(site))
colsc <- function(...) {
  scale_fill_gradientn(colours = rev(RColorBrewer::brewer.pal(11,"RdYlBu")),
                       limits = range(..., na.rm = TRUE))
}
csc <- colsc(pred_mesh@data["median"],
             pred_mesh@data["q0.025"],
             pred_mesh@data["q0.975"]) ## Common colour scale from SpatialPixelsDataFrame
site_mean <- ggplot() +
  gg(pred_mesh) +
  gg(flanders) +
  csc +
  coord_fixed()
site_q0.025 <- ggplot() +
  gg(pred_mesh["q0.025"]) +
  gg(flanders) +
  csc +
  coord_fixed()
site_q0.975 <- ggplot() +
  gg(pred_mesh["q0.975"]) +
  gg(flanders) +
  csc +
  coord_fixed()
site_cv <- ggplot() +
  gg(pred_mesh["cv"]) +
  gg(flanders) +
  coord_fixed()
multiplot(site_mean, site_q0.025, site_cv, site_q0.975, cols = 2)
```

