{
  "hash": "8d6d109359c5cf7221bce58a00e2e9f6",
  "result": {
    "markdown": "---\ntitle: Nested and crossed random effects in `lme4`\nauthor: Thierry Onkelinx\ndate: \"2017-07-18\"\ncategories: [statistics, mixed models]\nimage: /statistics/mixed-models/index_files/figure-html/fig-school-design-1.svg\nbibliography: ../../references.bib\nknitr:\n  opts_chunk: \n    dev: \"svg\"\n---\n\n\nPeople often get confused on how to code nested and crossed random effects in the [`lme4`](https://cran.r-project.org/package=lme4) package [@lme4].\nI will try to make this more clear using some artificial data sets.\n\n## Nested random effects\n\nNested random effects assume that there is some kind of hierarchy in the grouping of the observations.\nE.g. schools and classes.\nA class groups a number of students and a school groups a number of classes.\nThere is a one-to-many relationship between the random effects.\nE.g. a school can contain multiple classes but a class can only be part of one school.\nLets start by creating a simple example with fake data to explain the design.\nThe figure shows the contingency matrix for the dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nset.seed(123)\nn_school <- 10\nmean_n_class <- 7\nmean_n_student <- 5\n\nn_class <- rpois(n_school, mean_n_class)\nschools <- map2_df(\n  seq_len(n_school), \n  n_class, \n  ~tibble(\n    school = .x, \n    class = seq_len(.y),\n    students = rpois(.y, mean_n_student)\n  )\n) %>%\n  group_by(school, class) %>%\n  do(\n    student = tibble(student = seq_len(.$students))\n  ) %>%\n  unnest(student) %>%\n  mutate(\n    class2 = interaction(class, school, drop = TRUE),\n    student2 = interaction(class2, student, drop = TRUE)\n  )\n```\n:::\n\n\n`schools` contains 3 design variables: `school`, `class` and `student`.\nEach numbering restarts at 1 when the higher level number changes (@fig-school-design).\nHence the id of class and student are not unique.\nTherefore I added two new variables `class2` and `student2` which are unique id's for each class and student.\nThe next step is adding the expected and observed values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(schools, table(class2, school)) %>%\n  image(\n    col = grey.colors(10, start = 1, end = 0), \n    axes = FALSE, \n    xlab = \"Class\", \n    ylab = \"School\"\n  )\n```\n\n::: {.cell-output-display}\n![Contingency matrix for the `schools`data set](index_files/figure-html/fig-school-design-1.svg){#fig-school-design fig-alt='Contingency matrix for the `schools`data set' width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nschool_sd <- 2\nclass_sd <- 2\nnoise_sd <- 1\nintercept <- 50\n\nschool_effect <- rnorm(n_school, mean = 0, sd = school_sd)\nclass_effect <- rnorm(length(levels(schools$class2)), mean = 0, sd = class_sd)\nschools <- schools %>%\n  mutate(\n    mu = intercept + school_effect[school] + class_effect[class2],\n    y = mu + rnorm(n(), mean = 0, sd = noise_sd)\n  )\n```\n:::\n\n\n### Explicit nesting\n\nThe first option is to use explicit nesting.\nHere we add a random effect for each hierarchical level and use the `:` notation to add all higher levels.\nThis can be expanded to more than two levels.\nE.g. `(1|A) + (1|A:B) + (1|A:B:C) + (1|A:B:C:D)`.\nThe nice thing about this notation is twofold: a) the nesting is explicit and clear for all readers; b) it is insensitive for the order: e.g.\n`(1|A) + (1|A:B)` is identical to `(1|B:A) + (1|A)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlmer(y ~ (1|school) + (1|school:class), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | school) + (1 | school:class)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups       Name        Std.Dev.\n school:class (Intercept) 1.631   \n school       (Intercept) 1.806   \n Residual                 1.073   \nNumber of obs: 366, groups:  school:class, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n\n```{.r .cell-code}\nlmer(y ~ (1|class:school) + (1|school), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | class:school) + (1 | school)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups       Name        Std.Dev.\n class:school (Intercept) 1.631   \n school       (Intercept) 1.806   \n Residual                 1.073   \nNumber of obs: 366, groups:  class:school, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n:::\n\n\n### Shorthand nesting\n\n`(1|A) + (1|A:B)` can be abbreviated into `(1|A/B)`.\nHowever, I recommend against it because here the order is important as seen in the example below.\n`(1|B/A)` expands to `(1|B) + (1|B:A)`, which is clearly a different model than `(1|A) + (1|A:B)`.\nI've seen many people being confused about the order, therefore I recommend to be explicit instead of using shorthand.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmer(y ~ (1|school/class), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | school/class)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups       Name        Std.Dev.\n class:school (Intercept) 1.631   \n school       (Intercept) 1.806   \n Residual                 1.073   \nNumber of obs: 366, groups:  class:school, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n\n```{.r .cell-code}\nlmer(y ~ (1|class/school), data = schools)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nboundary (singular) fit: see help('isSingular')\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | class/school)\n   Data: schools\nREML criterion at convergence: 1320.039\nRandom effects:\n Groups       Name        Std.Dev.\n school:class (Intercept) 2.330   \n class        (Intercept) 0.000   \n Residual                 1.073   \nNumber of obs: 366, groups:  school:class, 74; class, 11\nFixed Effects:\n(Intercept)  \n      50.42  \noptimizer (nloptwrap) convergence code: 0 (OK) ; 0 optimizer warnings; 1 lme4 warnings \n```\n:::\n:::\n\n\n### Implicit nesting\n\nWith implicit nesting, the nesting is 'defined' in the data.\nThat is each level of a random effect has a one-to-many relation with the levels of the lower random effect.\nE.g. each class id is unique for a given class in a given school and cannot refer to a class in any other school.\nThis is how we constructed the `class2` variable in our data.\nWith implicit nesting the code can be abbreviated to `(1|A) + (1|B)`.\nNote that the `(1|A) + (1|A:B)` and `(1|A/B)` notations remain valid.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmer(y ~ (1|school) + (1|class2), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | school) + (1 | class2)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups   Name        Std.Dev.\n class2   (Intercept) 1.631   \n school   (Intercept) 1.806   \n Residual             1.073   \nNumber of obs: 366, groups:  class2, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n\n```{.r .cell-code}\nlmer(y ~ (1|school) + (1|school:class2), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | school) + (1 | school:class2)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups        Name        Std.Dev.\n school:class2 (Intercept) 1.631   \n school        (Intercept) 1.806   \n Residual                  1.073   \nNumber of obs: 366, groups:  school:class2, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n\n```{.r .cell-code}\nlmer(y ~ (1|school/class2), data = schools)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | school/class2)\n   Data: schools\nREML criterion at convergence: 1290.668\nRandom effects:\n Groups        Name        Std.Dev.\n class2:school (Intercept) 1.631   \n school        (Intercept) 1.806   \n Residual                  1.073   \nNumber of obs: 366, groups:  class2:school, 74; school, 10\nFixed Effects:\n(Intercept)  \n      50.27  \n```\n:::\n:::\n\n\n## Crossed random effects\n\nCrossed random effects appear when two (or more) variables can be used to create distinct groupings.\nThink about factories and products where a factory can produce a range of products, and a product can be manufactured in different factories.\nThe contigency matrix of such a design is shown in the next figure.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_factory <- 10\nn_product <- 10\nmean_n_sample <- 5\n\nfactories <- expand.grid(\n  factory = seq_len(n_factory),\n  product = seq_len(n_product)\n) %>%\n  mutate(\n    samples = rpois(n(), mean_n_sample)\n  ) %>%\n  group_by(factory, product) %>%\n  do(\n    sample = tibble(sample = seq_len(.$samples))\n  ) %>%\n  unnest(sample) %>%\n  mutate(\n    sample2 = interaction(factory, product, sample, drop = TRUE)\n  )\n```\n:::\n\n\n`factories` contains 3 design variables: `factory`, `product` and `sample`.\nMost of the `factory` and `product` combinations are present in the data and they are meaningful.\nProduct 1 in factory 1 is the same product as product 1 in factory 2 (@fig-factory-design).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(factories, table(product, factory)) %>%\n  image(\n    col = grey.colors(10, start = 1, end = 0), \n    axes = FALSE, \n    xlab = \"Product\", \n    ylab = \"Factory\"\n  )\n```\n\n::: {.cell-output-display}\n![Contingency matrix for the `factories`data set](index_files/figure-html/fig-factory-design-1.svg){#fig-factory-design width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfactory_sd <- 3\nproduct_sd <- 2\nnoise_sd <- 1\nintercept <- 50\n\nfactory_effect <- rnorm(n_factory, mean = 0, sd = factory_sd)\nproduct_effect <- rnorm(n_product, mean = 0, sd = product_sd)\nfactories <- factories %>%\n  mutate(\n    mu = intercept + factory_effect[factory] + product_effect[product],\n    y = mu + rnorm(n(), mean = 0, sd = noise_sd)\n  )\n```\n:::\n\n\n### Coding\n\nThe coding for crossed random effects is easy: `(1|A) + (1|B) + (1|C)`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmer(y ~ (1|factory) + (1|product), data = factories)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: y ~ (1 | factory) + (1 | product)\n   Data: factories\nREML criterion at convergence: 1461.96\nRandom effects:\n Groups   Name        Std.Dev.\n factory  (Intercept) 2.8210  \n product  (Intercept) 1.6837  \n Residual             0.9957  \nNumber of obs: 481, groups:  factory, 10; product, 10\nFixed Effects:\n(Intercept)  \n      49.36  \n```\n:::\n:::\n\n\n## Recommendations\n\n- each level of a random effect should be defined by a single variable: e.g. `class2` and `student2` in `schools`; `factory`, `product` and `sample2` in `factories`\n- use explicit nesting even when the data set would allow implicit nesting\n- don't use the shorthand nesting\n\n## Session info\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessioninfo::session_info()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.3.1 (2023-06-16)\n os       Ubuntu 22.04.3 LTS\n system   x86_64, linux-gnu\n ui       X11\n language nl_BE:nl\n collate  nl_BE.UTF-8\n ctype    nl_BE.UTF-8\n tz       Europe/Brussels\n date     2023-08-15\n pandoc   3.1.1 @ /usr/lib/rstudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version    date (UTC) lib source\n boot          1.3-28.1   2022-11-22 [1] CRAN (R 4.3.0)\n cli           3.6.1      2023-03-23 [1] CRAN (R 4.3.0)\n colorspace    2.1-0      2023-01-23 [1] CRAN (R 4.3.0)\n digest        0.6.33     2023-07-07 [1] CRAN (R 4.3.1)\n dplyr       * 1.1.2      2023-04-20 [1] CRAN (R 4.3.0)\n evaluate      0.21       2023-05-05 [1] CRAN (R 4.3.0)\n fansi         1.0.4      2023-01-22 [1] CRAN (R 4.3.0)\n fastmap       1.1.1      2023-02-24 [1] CRAN (R 4.3.0)\n forcats     * 1.0.0      2023-01-29 [1] CRAN (R 4.3.0)\n generics      0.1.3      2022-07-05 [1] CRAN (R 4.3.0)\n ggplot2     * 3.4.2      2023-04-03 [1] CRAN (R 4.3.0)\n glue          1.6.2      2022-02-24 [1] CRAN (R 4.3.0)\n gtable        0.3.3      2023-03-21 [1] CRAN (R 4.3.0)\n hms           1.1.3      2023-03-21 [1] CRAN (R 4.3.0)\n htmltools     0.5.6      2023-08-10 [1] CRAN (R 4.3.1)\n htmlwidgets   1.6.2      2023-03-17 [1] CRAN (R 4.3.0)\n jsonlite      1.8.7      2023-06-29 [1] CRAN (R 4.3.1)\n knitr         1.43       2023-05-25 [1] CRAN (R 4.3.0)\n lattice       0.21-8     2023-04-05 [4] CRAN (R 4.3.0)\n lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.3.0)\n lme4        * 1.1-34     2023-07-04 [1] CRAN (R 4.3.1)\n lubridate   * 1.9.2.9000 2023-08-07 [1] Github (tidyverse/lubridate@cae67ea)\n magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.3.0)\n MASS          7.3-60     2023-05-04 [4] CRAN (R 4.3.1)\n Matrix      * 1.6-0      2023-07-08 [1] CRAN (R 4.3.1)\n minqa         1.2.5      2022-10-19 [1] CRAN (R 4.3.0)\n munsell       0.5.0      2018-06-12 [1] CRAN (R 4.3.0)\n nlme          3.1-163    2023-08-09 [1] CRAN (R 4.3.1)\n nloptr        2.0.3      2022-05-26 [1] CRAN (R 4.3.0)\n pillar        1.9.0      2023-03-22 [1] CRAN (R 4.3.0)\n pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.3.0)\n purrr       * 1.0.2      2023-08-10 [1] CRAN (R 4.3.1)\n R6            2.5.1      2021-08-19 [1] CRAN (R 4.3.0)\n Rcpp          1.0.11     2023-07-06 [1] CRAN (R 4.3.1)\n readr       * 2.1.4      2023-02-10 [1] CRAN (R 4.3.0)\n rlang         1.1.1      2023-04-28 [1] CRAN (R 4.3.0)\n rmarkdown     2.23       2023-07-01 [1] CRAN (R 4.3.1)\n rstudioapi    0.15.0     2023-07-07 [1] CRAN (R 4.3.1)\n scales        1.2.1      2022-08-20 [1] CRAN (R 4.3.0)\n sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.3.0)\n stringi       1.7.12     2023-01-11 [1] CRAN (R 4.3.0)\n stringr     * 1.5.0      2022-12-02 [1] CRAN (R 4.3.0)\n tibble      * 3.2.1      2023-03-20 [1] CRAN (R 4.3.0)\n tidyr       * 1.3.0      2023-01-24 [1] CRAN (R 4.3.0)\n tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.3.0)\n tidyverse   * 2.0.0      2023-02-22 [1] CRAN (R 4.3.0)\n timechange    0.2.0      2023-01-11 [1] CRAN (R 4.3.0)\n tzdb          0.4.0      2023-05-12 [1] CRAN (R 4.3.0)\n utf8          1.2.3      2023-01-31 [1] CRAN (R 4.3.0)\n vctrs         0.6.3      2023-06-14 [1] CRAN (R 4.3.0)\n withr         2.5.0      2022-03-03 [1] CRAN (R 4.3.0)\n xfun          0.40       2023-08-09 [1] CRAN (R 4.3.1)\n yaml          2.3.7      2023-01-23 [1] CRAN (R 4.3.0)\n\n [1] /home/thierry/R/x86_64-pc-linux-gnu-library/4.3\n [2] /usr/local/lib/R/site-library\n [3] /usr/lib/R/site-library\n [4] /usr/lib/R/library\n\n──────────────────────────────────────────────────────────────────────────────\n```\n:::\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}