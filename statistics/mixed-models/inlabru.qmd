---
title: Comparing inlabru with INLA
author: Thierry Onkelinx
date: "2018-02-16"
categories: [statistics, mixed-models]
image: inlabru_files/figure-html/fig-plot-fixed-1.svg
knitr:
  opts_chunk: 
    dev: "svg"
    echo: true
    message: false
---

[`inlabru`](https://www.inlabru.org) is an R package which builds on top of the [`INLA`](https://www.r-inla.org) package.
I had the opportunity to take a workshop on it during the International Statistical Ecology Workshop [ISEC2018](https://www.isec2018.org) in St Andrews.
This was a five day workshop condensed into a single day, hence the pace was very high.
It gave us a good overview of the possibilities of `inlabru` but no time to try it on our own data.
_This is an updated version of the original post due to changes in the package used in the original post._

`inlabru` has two main functions: [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) and [`lgcp()`](https://inlabru-org.github.io/inlabru/reference/lgcp.html).
[`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) is a wrapper for `INLA::inla()`.
[`lgcp()`](https://inlabru-org.github.io/inlabru/reference/lgcp.html) is intended to fit log Gaussian Cox processes.
I will focus on `bru` and compare it with `INLA::inla()` as I find that [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) makes things a lot easier.

# Tundra bean goose

The test data is derived from the "Wintering waterbirds in Flanders, Belgium", freely available at GBIF (https://doi.org/10.15468/lj0udq).
I've extracted the observations from the [tundra bean goose](https://www.gbif.org/species/6178319) (_Anser fabalis rossicus_, @fig-tundra-bean-goose).
The dataset was limited to those locations with at least 6 occurrences during at least 3 years.
Months with lower number of count were removed.
@fig-observed-total indicates the sum of all observed geese in the data.
Note that these totals are somewhat misleading since there are a fair amount of missing observations (@fig-missing).
The geographic distribution of the data is given in @fig-map-goose.

![Tundra bean goose _Anser fabalis rossicus_ by [Roar Ottesen](https://www.gbif.org/occurrence/1798469433) CC BY 4.0](media/tundra-bean-goose.jpg){#fig-tundra-bean-goose}

```{r}
#| label: load-packages
library(leaflet)
library(scales)
library(sf)
library(tidyverse)
goose <- readRDS("data/anser_fabalis_rossicus.Rds")
set.seed(20180712)
```

```{r}
#| label: fig-observed-total
#| fig-cap: Time series of observed total counts for tundra bean goose
#| echo: false
goose |>
  group_by(.data$year, .data$month) |>
  summarise(observed = sum(.data$count), .groups = "drop") |>
  ggplot(aes(x = year, y = observed, colour = month)) +
  geom_line()
```

```{r}
#| label: fig-missing
#| fig-cap: Time series of missingness in the data
#| echo: false
goose |>
  complete(.data$location_id, .data$year, .data$month) |>
  group_by(.data$year, .data$month) |>
  summarise(missing = mean(is.na(.data$count)), .groups = "drop") |>
  ggplot(aes(x = year, colour = month, y = missing)) +
  geom_line() +
  scale_y_continuous("proportion of missing counts", labels = percent)
```

```{r}
#| label: fig-map-goose
#| fig-cap: "Map with the locations for tundra bean goose.
#|   The circle markers represent the centroid of the site. The area of the
#|   circle is proportional to the mean of the observed counts."
#| echo: false
goose |>
  group_by(location_id, lat, long) |>
  summarise(mean = mean(count)) |>
  mutate(mean = 2 * sqrt(mean / pi)) |>
  leaflet() |>
  addTiles() |>
  addCircleMarkers(radius = ~mean)
```

# `INLA` vs `inlabru`

## Fixed effects only

Let's start with a very simple model with contains only the year centred to the last year.
The syntax of both models is very similar.
[`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) is a bit shorted because it returns both $WAIC$ and $DIC$ by default.
The models are identical because [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) is just a wrapper for `inla()`.
Their summary output is somewhat different in terms of lay-out and which information is given.

```{r}
#| label: load-inla
library(INLA)
library(inlabru)
```

```{r}
#| label: fixed-continous
goose |>
  mutate(cyear = .data$year - max(.data$year)) -> goose
m0_inla <- inla(
  count ~ cyear,  data = goose,  family = "nbinomial",
  control.compute = list(waic = TRUE, dic = TRUE)
)
m0_inlabru <- bru(count ~ cyear, data = goose, family = "nbinomial")
summary(m0_inla)
summary(m0_inlabru)
```

A drawback is that [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) doesn't handle factor fixed effects.
In a previous version it yielded a warning about invalid factor levels when fitting the model.
Unfortunately you didn't get the warning when getting the summary.
You needed to be critical and noticed that the parameters of the model are not what you would expect.
The current version throws a criptic error.
The workaround is to convert the factor variable into a set of dummy variables and use those.
Creating the dummy variable is straight forward with `model.matrix()`.
But adding them to the model is not very efficient when you have factor variables with more than a just few levels.

```{r}
#| label: fixed-factor
#| error: true
m1_inla <- inla(
  count ~ cyear + month, data = goose, family = "nbinomial",
  control.compute = list(waic = TRUE, dic = TRUE)
)
m1_inlabru <- bru(count ~ cyear + month, data = goose, family = "nbinomial")
summary(m1_inla)
goose |> 
  model.matrix(object = ~month) |>
  as.data.frame() |>
  select(-1) |>
  bind_cols(goose) -> goose
m1_inlabru <- bru(
  count ~ cyear + monthdec + monthjan + monthfeb, data = goose,
  family = "nbinomial"
)
summary(m1_inlabru)
```

## Random effects

`inla()` use the `f()` function to specify the random effects.
[`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) is very liberal and allows the user to choose any name, as long as it is a valid function name.
In the example below we use `site`.
For more detail see `help("bru.components")`.
The downside is that [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) requires integer coded levels which go from 1 to the number of levels.
We use the `as.integer(factor())` trick to get these indices.
Furthermore you need to supply the number of levels in the random effect for some random effects models.

```{r random-iid}
comp_inla <- count ~ cyear + month + f(location_id, model = "iid")
m2_inla <- inla(
  comp_inla, data = goose, family = "nbinomial",
  control.compute = list(waic = TRUE, dic = TRUE)
)
goose |>
  mutate(
    loc_id = factor(.data$location_id) |>
      as.integer()
  ) -> goose
n_loc <- max(goose$loc_id)
comp_inlabru <- count ~ cyear + monthdec + monthjan + monthfeb + 
  site(main = loc_id, model = "iid", n = n_loc)
m2_inlabru <- bru(comp_inlabru, data = goose, family = "nbinomial")
summary(m2_inla)
summary(m2_inlabru)
```

The use of user defined names for random effect functions has the benefit that you can use the same variable multiple times in the model.
`inla()` requires unique names and hence copies of the variable.
The `main` argument also allows to use a function of a variable, thus removing the need of creating a new variable.
The `model = "linear"` is another way of specifying a continuous fixed effect.
See http://www.r-inla.org/models/latent-models for an overview of all available latent models in INLA.

```{r random-alternatives}
goose |>
  mutate(
    cyear = .data$cyear - min(.data$cyear) + 1,
    cyear2 = .data$cyear
  ) -> goose2
n_year <- max(goose2$cyear)
comp_inla <- count ~ cyear + f(cyear2, model = "iid") + 
  month + f(location_id, model = "iid")
m3_inla <- inla(
  comp_inla, data = goose2, family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
comp_inlabru <- count ~ cyear + monthdec + monthjan + monthfeb +
  rtrend(main = cyear, model = "iid", n = n_year) +
  site(main = loc_id, model = "iid", n = n_loc)
m3_inlabru <- bru(comp_inlabru, data = goose2, family = "nbinomial")
comp_inlabru <- count ~ 
  lintrend(main = cyear, model = "linear") + 
  quadtrend(main = cyear ^ 2, model = "linear") +
  rtrend(main = cyear, model = "iid", n = n_year) +
  monthdec + monthjan + monthfeb + site(main = loc_id, model = "iid", n = n_loc)
m3_inlabru2 <- bru(comp_inlabru, data = goose2, family = "nbinomial")
summary(m3_inlabru2)
```

## Meshed random effects

One of the great benefits of `inlabru` is that it makes it much easier to work with random effects on a mesh.
The current data are geographic coordinates in "WGS84".
For this analysis we want them in a projected coordinate system. "Belgian Lambert 72" [EPSG:31370](https://epsg.io/31370) is a relevant choice.
Therefore we convert the data into a `SpatialPointsDataFrame` and transform it to EPSG:31370.

Instead of using a convex hull of the locations, we will use the administrative borders of [Flanders](https://en.wikipedia.org/wiki/Flanders) as a boundary for the mesh.
The simplified version of this border is the blue line in @fig-flanders-mesh.
Note that the mesh extents this border because that reduces potential edge effects.
The detail of the mesh is defined by `cutoff` and `max.edge`, the former defines the minimal length of each edge and the latter the maximal length.
These lengths have the same units as the coordinate system, in this case meters.
We pass two numbers for both arguments.
The first refers to the edges inside the boundary, the second to edges outside the boundary.
This creates larger triangles outside the boundary, which will speed up the computation.

```{r}
#| label: fig-flanders-mesh
#| fig-cap: Mesh for Flanders. Red circles indicate the sites.,
#| message: false
st_as_sf(goose, coords = c("long", "lat"), crs = st_crs(4326)) |>
  st_transform(st_crs(31370)) -> goose_lambert
read_sf("data/vlaanderen.shp") -> flanders
as.inla.mesh.segment(flanders) -> flanders_segment
inla.mesh.2d(
  boundary = flanders_segment, max.edge = c(10e3, 20e3), cutoff = c(5e3, 10e3)
) -> flanders_mesh
ggplot() +
  gg(flanders_mesh) +
  geom_sf(data = goose_lambert, col = "red") +
  coord_sf()
```

Once the mesh is defined, we can create the [stochastic partial differential equation](https://en.wikipedia.org/wiki/Stochastic_partial_differential_equation) SPDE model.
In this case we define it using a [Matérn covariance function](https://en.wikipedia.org/wiki/Mat%C3%A9rn_covariance_function).

```{r}
#| label: spde
flanders_spde <- inla.spde2.pcmatern(
  flanders_mesh, prior.range = c(1e3, 0.99), prior.sigma = c(4, 0.01)
)
```

All steps up to this point are needed for both `INLA::inla()` and [`inlabr::bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html).
In case of `INLA::inla()` you need use `inla.spde.make.A()` to define a project matrix.
This matrix maps the coordinates of the observation to the three nodes of the triangle in which it is located.
In the special case that the observation is on a edge it will map to the two nodes defining the edge, or the node itself in case the observation coincides with a node.
Then you need to define a `inla.stack()`, which is passed to the `data` argument after transforming it with `inla.stack.data()`.
The SPDE object is used as `model` in the random effect "site".

The same model is much easier with  [`inlabr::bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html).
In this case you need to pass a `SpatialPointsDataFrame` to the `data` argument.
The random effect "site" has the SPDE object as `model` and uses "coordinates" as `main`.
In this case there is no object "coordinates" in the data, hence `inlabr::bru()` will look in the environment and finds the `sf::st_coordinates()` function.
This functions returns the coordinates of an `sf` object, so [`inlabr::bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html) has all the information it needs to map the observations to the SPDE object.

```{r}
#| label: fit-spde
## INLA
A <- inla.spde.make.A(mesh = flanders_mesh, loc = goose_lambert)
goose_stack <- inla.stack(
  tag = 'estimation', ## tag
  data = list(count = goose$count), ## response
  A = list(A, 1), ## two projector matrices (SPDE and fixed effects)
  effects = list(## two elements:
    site = seq_len(flanders_spde$n.spde), ## RF index
    goose |>
      select("cyear", "month")
  )
)
comp_inla <- count ~ 0 + month + cyear + f(site, model = flanders_spde)
m4_inla <- inla(
  comp_inla, data = inla.stack.data(goose_stack), family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE),
  control.predictor = list(A = inla.stack.A(goose_stack))
)

# inlabru
comp_inlabru <- count ~ monthdec + monthjan + monthfeb + cyear +
  site(main = st_coordinates, model = flanders_spde)
m4_inlabru <- bru(comp_inlabru, data = goose_lambert, family = "nbinomial")
```

We can also create 1 dimensional meshes.
This is useful for line transects or (irregular) time series.

```{r}
#| label: fit-spde-2
trend_mesh <- inla.mesh.1d(min(goose$year):max(goose$year), boundary = "free")
trend_spde <- inla.spde2.pcmatern(
  trend_mesh, prior.range = c(1, 0.5), prior.sigma = c(4, 0.01)
)
comp_inlabru <- count ~ monthdec + monthjan + monthfeb +
  trend(main = year, model = trend_spde) +
  site(main = st_coordinates, model = flanders_spde)
m4b_inlabru <- bru(comp_inlabru, data = goose_lambert, family = "nbinomial")
```

## Plotting the model

`plot.inla()` is an easy way to generate most of the relevant plots with a single command.
It will open several plot windows to keep the plots readable.
However this doesn't work well in combination with Rmarkdown.
`plot.bru()` has the opposite philosophy: you get the plot of only one component.
Getting a plot for all components is a bit more tedious, but the advantage is that you can use it in combination with Rmarkdown.
Another nice feature is that `plot.bru()` returns `ggplot2` object.
So they are easy to adapt, see e.g. @fig-plot-fixed.
`inlabru` also provides a `multiplot()` function which can be used to combine several plots.

```{r}
#| label: rw1-models
pc_prior <- list(theta = list(prior = "pc.prec", param = c(1, 0.01)))
goose |>
  mutate(iyear = .data$cyear - min(.data$cyear) + 1) -> goose
n_year <- max(goose$iyear)
comp_inla <- count ~ month + 
  f(cyear, model = "rw1", hyper = pc_prior) + 
  f(location_id, model = "iid", hyper = pc_prior)
m5_inla <- inla(
  comp_inla, data = goose, family = "nbinomial", 
  control.compute = list(waic = TRUE, dic = TRUE)
)
comp_inlabru <- count ~ monthdec + monthjan + monthfeb + 
  trend(main = iyear, model = "rw1", n = n_year, hyper = pc_prior) +
  site(main = loc_id, model = "iid", n = n_loc, hyper = pc_prior)
m5_inlabru <- bru(comp_inlabru, data = goose, family = "nbinomial")
```

```{r}
#| label: plot-inla
#| eval: false
plot(m5_inla)
```

```{r}
#| label: fig-plot-fixed
#| fig-cap: Posterior density plots of the fixed effects
p_intercept <- plot(m5_inlabru, "Intercept") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthdec <- plot(m5_inlabru, "monthdec") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthjan <- plot(m5_inlabru, "monthjan") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
p_monthfeb <- plot(m5_inlabru, "monthfeb") + 
  geom_vline(xintercept = 0, linetype = 2) +
  xlim(-1, 4)
multiplot(p_intercept, p_monthdec, p_monthjan, p_monthfeb)
```

```{r}
#| label: fit-plot-trend
#| fig-cap: Posterior density of the trend random intercepts.
plot(m5_inlabru, "trend")
```

```{r}
#| label: fig-site
#| fig-cap: Posterior density of the site random intercepts."
plot(m5_inlabru, "site")
```

### Plotting meshes

The mesh effects can be plot in a similar way.
The default plot will display the estimate effect at each node.
While this can be useful for 1D plot with a small number of nodes (top of @fig-mesh-plot), this is not useful for 2D meshes or meshed with a large number of nodes (bottom of @fig-mesh-plot).
Looking at the posterior distributions for the range and the variance of the Matérn covariance structure of SPDE model makes more sense [@fig-mesh-range-var].
Or plot the actual Matérn functions [@fig-matern-function].

```{r}
#| label: fig-mesh-plot
#| fig-cap: Posterior density of the random intercepts at the nodes of the mesh.
p_trend <- plot(m4b_inlabru, "trend")
p_site <- plot(m4b_inlabru, "site")
multiplot(p_trend, p_site)
```

```{r}
#| label: fig-mesh-range-var
#| fig-cap: Posterior distributions of the range and log variance of the Matérn covariace for the sites.
spde_range <- spde.posterior(m4b_inlabru, "site", what = "range")
spde_logvar <- spde.posterior(m4b_inlabru, "site", what = "log.variance")
range_plot <- plot(spde_range)
var_plot <- plot(spde_logvar)
multiplot(range_plot, var_plot)
```

```{r}
#| label: fig-matern-function
#| fig-cap: Fitted Matérn covariance and correlation functions.
spde.posterior(m4b_inlabru, "site", what = "matern.covariance") |>
  plot() +
  xlab("distance") +
  ylab("covariance") -> covplot
spde.posterior(m4b_inlabru, "site", what = "matern.correlation") |>
  plot()  +
  xlab("distance") +
  ylab("correlation") -> corplot
multiplot(covplot, corplot)
```

# Predictions

`INLA` has, unlike most R packages, no `predict()` function.
So `INLA` can't do predictions? No, it can do prediction but it does that simultaneously with fitting the model.
This implies that you need to add the observations for which you want prediction to the data prior to the model fitting.
Setting the response variable to `NA` avoid that these observation influence the model parameters.
A huge downside of this is, that you need to plan ahead and carefully prepare your data.
If you forget some prediction, you will have to fit the model again. 

The `predict()` function in most R packages split the model fitting and the prediction in two separate steps.
Getting prediction for another data set does not require to refit the model.
`inlabru` provided a `predict()` function for [`bru()`](https://inlabru-org.github.io/inlabru/reference/bru.html),
[`lgcp()`](https://inlabru-org.github.io/inlabru/reference/lgcp.html) and `inla` models.
The fitting works slightly different in `INLA` and `inlabru`.
When the observations for the prediction are available at the time of the model fitting, then the full posterior of those observations becomes available.
`inlabru::predict.inla()` works by repeatedly sampling the posterior distributions of the parameters and use each sample to calculate a predicted values.
This yields a sampled posterior distribution for the fitted value of the observations.

`predict.bru()` requires at least three arguments: `object` the fitted model; `data` the new observations for which you want a prediction and `formula` the components of the model you want to use in the predictions.
The example below calculates the predictions for only the trend component.
Note that the predict function returns the `data` and adds several columns with relevant information on the prediction.
The names of these columns are more efficient than those returned by `INLA`: `q0.025` is a valid name for an R object, whereas `0.025quant` isn't.
Another nice feather is that you can incorporate the prediction directly into a `ggplot2` plot.

```{r}
#| label: predictions
goose |>
  distinct(.data$year, .data$iyear) |>
  predict(object = m5_inlabru, formula = ~ trend) -> pred_trend_log
# predictions from inlabru
glimpse(pred_trend_log)
# fitted value from INLA
glimpse(m5_inla$summary.fitted.values)
```

```{r}
#| label: fig-trend-prediction
#| fig-cap: Predicted effect of `trend` on the link scale.
ggplot() +
  gg(pred_trend_log) +
  geom_hline(yintercept = 0, linetype = 2)
```

The default prediction are on the link scale, which is the log link in this case.
Back-transformation is straightforward, just add the back transformation function to the formula.

```{r}
#| label: fig-trend-prediction-natural
#| fig-cap: Predicted effect of 'trend' on the natural scale
goose |>
  distinct(.data$year, .data$iyear) |>
  predict(object = m5_inlabru, formula = ~ exp(trend)) -> pred_trend_natural
ggplot() +
  gg(pred_trend_natural) +
  geom_hline(yintercept = 1, linetype = 2)
```

The `gg()` solutions works only in case of a single covariate.
With multiple covariate you have to create the plot manually.
But that is not very hard given the nice format of the output returned by `predict.bru()`.

```{r}
#| label: fig-prediction-average
#| fig-cap: Predicted average expected mean of the counts.
goose |>
  distinct(
    .data$year, .data$month, .data$iyear, .data$monthdec, .data$monthjan,
    .data$monthfeb
  ) |>
  predict(
    object = m5_inlabru, 
    formula = ~ exp(Intercept + trend + monthdec + monthjan + monthfeb)
  ) -> pred_trend_month
ggplot(pred_trend_month, aes(x = year, y = mean, ymin = q0.025, ymax = q0.975)) +
  geom_ribbon(aes(fill = month), alpha = 0.1) +
  geom_line(aes(colour = month))
```

Another very neat feature is that you can take both the model uncertainty as the natural variability into account.
The model estimates the mean of the negative binomial distribution.
The variability of this mean only includes the model uncertainty.
In case we are interested in the total variability in the count, we need to plug this mean into the distribution.
Below is an example on how to do this.
AFAIK this works only for a single prediction.
The result yields the distribution of the counts.
`inla.zmarginal` is used to calculate the mean and the quantiles of this distribution.
Please note that is not entirely correct as we are ignoring the variability of the dispersion parameter of the negative binomial distribution.
I'm not sure how to incorporate that at the moment.

```{r}
#| label: fig-distn
#| fig.cap: "Distribution of the average counts for the last year in January.
#| Dashed lines indicate the mean, 2.5% and 97.5% quantiles."
size <- 1 / m5_inlabru$summary.hyperpar[1, "mean"]
goose |>
  distinct(.data$year, .data$iyear, .data$month, .data$monthjan) |>
  filter(.data$year == max(.data$year), .data$month == "jan") |>
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      n = 0:450,
      dnbinom(0:450, size = size, mu = exp(Intercept + trend + monthjan))
    ),
    n.samples = 1e2
  ) -> pred_trend_natural_n
pred_trend_natural_n |>
  select(x = "n", y = "mean") |>
  as.list() |>
  inla.zmarginal(silent = TRUE) |>
  unlist() -> quants
ggplot(pred_trend_natural_n, aes(x = n, y = mean)) +
  geom_line() +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")],
    linetype = 2
  )
```

```{r}
#| label: fig-distn2
#| fig-cap: "Distribution of the average counts for the last year in January.
#| Dashed lines indicate the mean, 2.5% and 97.5% quantiles.
#| Black lines are based on 100 samples, red lines on 1000 samples."
goose |>
  distinct(.data$year, .data$iyear, .data$month, .data$monthjan) |>
  filter(.data$year == max(.data$year), .data$month == "jan") |>
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      n = 0:450,
      dnbinom(0:450, size = size, mu = exp(Intercept + trend + monthjan))
    ),
    n.samples = 1e3
  ) -> pred_trend_natural_n2
pred_trend_natural_n2 |>
  select(x = n, y = mean) |>
  as.list() |>
  inla.zmarginal(silent = TRUE) |>
  unlist() -> quants2
ggplot(pred_trend_natural_n, aes(x = n, y = mean)) +
  geom_line() +
  geom_line(data = pred_trend_natural_n2, colour = "red") +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")], linetype = 2
  ) +
  geom_vline(
    xintercept = quants2[c("mean", "quant0.025", "quant0.975")], linetype = 2,
    colour = "red"
  )
```

We can also use aggregations in the formula.
Let's say we want to estimate the total number of birds over all sites at a given year and month.
The example below illustrated how you can use aggregation.

```{r}
#| label: fig-distn3
#| fig-cap: "Distribution of the total counts for the last year in January.
#| Dashed lines indicate the mean, 2.5% and 97.5% quantiles."
# total of expected counts
goose |>
  filter(.data$year == max(.data$year), .data$month == "jan") |>
  predict(
    object = m5_inlabru, 
    formula = ~ exp(
      Intercept + trend + monthdec + monthjan + monthfeb + site
    ) |>
        sum()
  ) -> pred_total
glimpse(pred_total)
# distribution of total counts
low <- qnbinom(0.001, mu = pred_total$q0.025, size = size)
high <- qnbinom(0.999, mu = pred_total$q0.975, size = size)
goose |>
  filter(.data$year == max(.data$year), .data$month == "jan") |>
  predict(
    object = m5_inlabru, 
    formula =   ~ data.frame(
      n = low:high,
      dnbinom(
        low:high, size = size,
        mu = exp(Intercept + trend + monthdec + monthjan + monthfeb + site) |>
          sum()
      )
    )
  ) -> pred_total_natural
pred_total_natural |>
  select(x = "n", y = "mean") |>
  as.list() |>
  inla.zmarginal(silent = TRUE) |>
  unlist() -> quants
ggplot(pred_total_natural, aes(x = n, y = mean)) +
  geom_line() +
  geom_vline(
    xintercept = quants[c("mean", "quant0.025", "quant0.975")],
    linetype = 2
  )
```

We can make predictions for the mesh as well. 

```{r}
#| label: fig-prediction-mesh
#| fig-cap: Relative effect of the spatial field of the sites.
pred_mesh <- predict(
  m4b_inlabru, fm_pixels(flanders_mesh, nx = 80, ny = 30), ~exp(site)
)
st_crs(pred_mesh) <- 31370
site_mean <- ggplot() +
  geom_sf(data = pred_mesh, aes(colour = median)) +
  geom_sf(data = flanders, fill = NA, colour = "red", linewidth = 0.5)
site_q0.025 <- ggplot() +
  geom_sf(data = pred_mesh, aes(colour = q0.025)) +
  geom_sf(data = flanders, fill = NA, colour = "red", linewidth = 0.5)
site_q0.975 <- ggplot() +
  geom_sf(data = pred_mesh, aes(colour = q0.975)) +
  geom_sf(data = flanders, fill = NA, colour = "red", linewidth = 0.5)
site_cv <- ggplot() +
  geom_sf(data = pred_mesh, aes(colour = sd)) +
  geom_sf(data = flanders, fill = NA, colour = "red", linewidth = 0.5)
multiplot(site_mean, site_q0.025, site_cv, site_q0.975, cols = 2)
```

## Session info

```{r}
#| label: session-info
#| echo: false
sessioninfo::session_info()
```
